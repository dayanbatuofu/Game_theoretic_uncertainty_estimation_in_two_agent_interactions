/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'none'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'none'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation


parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'lane_change'], default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'complete_information', 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'],
                    default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point',
                             'reactive_uncertainty'], default=['baseline', 'baseline'])
                    #default=['constant_speed', 'constant_speed'])
parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])# default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])# default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='train_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='train_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    #default = ['constant_speed', 'constant_speed'])
                    default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'constant_speed'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'constant_speed'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
No handles with labels found to put in legend.
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline2'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline2'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline2'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline2'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline2'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline2'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=0.5)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=0.5, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=0.5)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=0.5, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['constant_speed', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['constant_speed', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection','lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default = ['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning

args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
<<<<<<< HEAD
=======
    print("Before similations")
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='merger')
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='merger', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
<<<<<<< HEAD
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
=======
C:\Users\samatya.ASURITE\Documents\GitHub\Social_Gracefulness_of_Autonomous_Systems\main.py
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
<<<<<<< HEAD
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
=======
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
<<<<<<< HEAD
                    default=['none', 'empathetic'])
=======
                    default=['none', 'trained_baseline'])
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information', 'reactive_point'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




<<<<<<< HEAD
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline2', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline2', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline2', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline2', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
/home/komon/savi/src/Social_Gracefulness_of_Autonomous_Systems/main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
=======
Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
>>>>>>> e81fd59f230f19ab794cad87545492e816e2a0e2
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'baseline'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'baseline'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'trained_baseline'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_point'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_point'], agent_dt=1, agent_inference=['none', 'trained_baseline'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])
                    #default=['baseline', 'baseline'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
#TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_uncertainty', 'reactive_uncertainty'],
                    default=['baseline', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['baseline', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_point', 'reactive_point'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_point', 'reactive_point'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
C:\Users\Kevin\PycharmProjects\Social_Gracefulness_of_Autonomous_Systems\main.py
"""
Use python main.py to execute!
Important files:
1. autonomous_vehicle: process and record agent info
2. inference_model: performs inference and prediction
3. decision_model: returns appropriate action for each agent
4. sim_draw: plots the simulation and results
5. >>> savi_simulation: executes the simulation <<<
Change the default values below to change actual model used!
"""
import os
import argparse
import utils
import torch as t
from environment import Environment
from savi_simulation import Simulation

parser = argparse.ArgumentParser()
"""
simulation parameters
"""
parser.add_argument('--sim_duration', type=int, default=100)  # time span for simulation
parser.add_argument('--sim_dt', type=int, default=1)  # time step in simulation
parser.add_argument('--sim_lr', type=float, default=0.1)  # learning rate
parser.add_argument('--sim_nepochs', type=int, default=100)  # number of training epochs
parser.add_argument('--save', type=str, default='./experiment')  # save dir
parser.add_argument('--debug', action='store_true')
parser.add_argument('--gpu', type=int, default=0)

"""
environment parameters
"""
parser.add_argument('--env_name', type=str, choices=['test_intersection', 'trained_intersection', 'lane_change', 'merger'],
                    default='trained_intersection')

"""
agent parameters
"""
# choose inference model: none: complete information
parser.add_argument('--agent_inference', type=str, choices=['none', 'test_baseline', 'trained_baseline', 'empathetic'],
                    default=['none', 'empathetic'])
# choose decision model: complete_information: nash equilibrium with complete information
parser.add_argument('--agent_decision', type=str,
                    choices=['constant_speed', 'baseline', 'baseline2', 'complete_information'
                             , 'reactive_point', 'reactive_uncertainty'],
                    default=['reactive_uncertainty', 'reactive_uncertainty'])

parser.add_argument('--agent_dt', type=int, default=1)  # time step in planning
# TODO: add agent decision args
# parser.add_argument('', type=str, choices=[], default=[])
args = parser.parse_args()


if __name__ == "__main__":
    utils.makedirs(args.save)
    logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    device = t.device('cuda:' + str(args.gpu) if t.cuda.is_available() else 'cpu')

    e = Environment(args.env_name)
    assert len(args.agent_inference) == e.n_agents and len(args.agent_decision) == e.n_agents

    kwargs = {"env": e,
              "duration": args.sim_duration,
              "n_agents": e.n_agents,
              "inference_type": args.agent_inference,
              "decision_type": args.agent_decision,
              "sim_dt": args.sim_dt,
              "sim_lr": args.sim_lr,
              "sim_nepochs": args.sim_nepochs}
    s = Simulation(**kwargs)
    s.run()

    # add analysis stuff here
    # s.postprocess()




Namespace(agent_decision=['reactive_uncertainty', 'reactive_uncertainty'], agent_dt=1, agent_inference=['none', 'empathetic'], debug=False, env_name='trained_intersection', gpu=0, save='./experiment', sim_dt=1, sim_duration=100, sim_lr=0.1, sim_nepochs=100)
